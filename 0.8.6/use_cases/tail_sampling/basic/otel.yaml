apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: trace-balancer
  namespace: mdai
spec:
  serviceAccount: loadbalancer
  image: otel/opentelemetry-collector-contrib:0.127.0
  replicas: 1
  resources:
    limits:
      memory: "256Mi"
      cpu: "200m"
    requests:
      memory: "128Mi"
      cpu: "100m"
  config:
    receivers:
      otlp/from_agent:
        protocols:
          grpc:
            endpoint: '0.0.0.0:4317'
          http:
            endpoint: '0.0.0.0:4318'

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133

    processors:
      deltatocumulative: {}

    exporters:
      loadbalancing:
        protocol:
          otlp:
            compression: gzip
            tls:
              insecure: true
        resolver:
          k8s:
            service: gateway-collector-headless.mdai
      prometheus:
        endpoint: 0.0.0.0:8899
        metric_expiration: 180m
        resource_to_telemetry_conversion:
          enabled: true

    connectors:
      count/service:
        spans:
          trace.span.service.count:
            description: Span count by service.
            conditions:
              - 'IsRootSpan()'

    service:
      telemetry:
        resource:
          mdai-logstream: collector
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: "0.0.0.0"
                    port: 8888
      extensions: [health_check]
      pipelines:
        traces:
          receivers: [otlp/from_agent]
          processors: []
          exporters: [loadbalancing, count/service]
        metrics:
          receivers: [count/service]
          processors: [deltatocumulative]
          exporters: [prometheus]
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: gateway
  namespace: mdai
spec:
  managementState: managed
  image: otel/opentelemetry-collector-contrib:0.127.0
  replicas: 3
  resources:
    limits:
      memory: "512Mi"
      cpu: "200m"
    requests:
      memory: "256Mi"
      cpu: "100m"
  config:
    receivers:
      otlp/from_lb:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317

    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"

    processors:
      batch:
        send_batch_size: 50
        send_batch_max_size: 200
        timeout: 10s

    exporters:
      debug/to_vendor:
        verbosity: detailed
    service:
      telemetry:
        resource:
          mdai-logstream: collector
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: "0.0.0.0"
                    port: 8888
      extensions: [health_check]
      pipelines:
        traces:
          # ensure metrics are computed before sampling, ensuring their accuracy
          receivers: [otlp/from_lb]
          processors: [batch]
          exporters: [debug/to_vendor]
